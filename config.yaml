# Pump.fun Data Scraper Configuration

# Primary API Configuration - Moralis (Recommended)
moralis_api_key: null  # REQUIRED: Get your API key from https://moralis.io
moralis_base_url: "https://solana-gateway.moralis.io"
use_moralis: true  # Set to true to use Moralis API (recommended)
moralis_poll_interval: 20  # Polling interval in seconds for Moralis API

# General API Configuration
base_url: "https://pump.fun"
timeout_seconds: 60
api_page_size: 100
api_extra_headers: {}

# Legacy PumpPortal API Configuration (Deprecated)
api_base_url: "https://pumpportal.fun"  # Official PumpPortal API (legacy)
websocket_url: "wss://pumpportal.fun/api/data"  # Official WebSocket API (legacy)
api_key: null  # Optional API key for PumpPortal (deprecated)

# Proxy Configuration
proxy_url: null  # Example: "http://user:pass@proxy:8000"
playwright_proxy: null  # Optional proxy for Playwright browser

# WebSocket Rate Limiting (for message processing)
rate_limit_rpm: 100  # Messages per minute (WebSocket can handle more)
rate_limit_rph: 5000  # Messages per hour
request_delay: 0.1  # Delay between WebSocket operations

# WebSocket & Data Collection Settings
websocket_reconnect_attempts: 5  # Max WebSocket reconnection attempts
websocket_reconnect_delay: 5.0  # Delay between reconnection attempts
websocket_ping_interval: 30.0  # WebSocket ping interval (seconds)
websocket_timeout: 60.0  # WebSocket connection timeout (seconds)
data_collection_duration: 300  # Duration to collect real-time data (seconds)

# Scraping Limits (for compatibility)
max_tokens: 1000  # Maximum tokens to collect in one session
max_tokens_for_transactions: 100  # Max tokens to get transaction data for
transactions_per_token: 200  # Number of transactions per token
new_launches_hours: 24  # Hours to look back for new launches

# Legacy Browser Configuration (deprecated - now uses official WebSocket API)
use_browser_fallback: false  # Deprecated - now uses official WebSocket API
headless_browser: true  # Run browser in headless mode
user_agent: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
preload_browser_cookies: true
browser_page_settle_delay: 1.5  # Seconds to wait after page load before syncing cookies
browser_request_timeout_ms: 30000  # Timeout for browser-based fetch requests (milliseconds)
cookie_sync_interval: 300  # Seconds before refreshing cookies from browser

# Output Configuration
output_directory: "data"  # Directory to save scraped data
output_format: "both"  # Output format: json, csv, or both
include_timestamps: true  # Include timestamps in output files

# Logging Configuration
log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
log_file: "logs/scraper.log"  # Log file path (null to disable file logging)

# Retry Configuration
max_retries: 5  # Maximum retries for failed requests
retry_delay: 5.0  # Delay between retries in seconds
max_retry_backoff: 45.0  # Maximum delay between retry attempts in seconds

# Data Filtering
min_market_cap: 0.0  # Minimum market cap to include (0 for all)
min_volume: 0.0  # Minimum 24h volume to include (0 for all)
exclude_rugged: true  # Attempt to exclude rugged/scam tokens
